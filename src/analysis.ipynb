{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/anlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import gc\n",
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\", model_kwargs={\"device\": \"cuda\"})\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={\"device\": \"cuda\"})\n",
    "vectorstore = Chroma(persist_directory=\"./chroma_db\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_inference(qa_chain, questions, batch_size, ground_truths=None):\n",
    "    \"\"\"\n",
    "    Processes the list of questions in batches and returns accumulated predictions.\n",
    "    If ground_truths are provided, computes and prints metrics for each batch.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    num_batches = (len(questions) + batch_size - 1) // batch_size\n",
    "\n",
    "    for i in range(0, len(questions), batch_size):\n",
    "        batch = questions[i:i+batch_size]\n",
    "        batch_inputs = [{\"query\": q} for q in batch]\n",
    "        # Use invoke to process the batch\n",
    "        with torch.no_grad():\n",
    "            if batch_size > 1:\n",
    "                batch_outputs = qa_chain.batch(batch_inputs)\n",
    "            else:\n",
    "                batch_outputs = [qa_chain.invoke(batch_inputs[0])]\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        batch_predictions = []\n",
    "        for output in batch_outputs:\n",
    "            # Handle different output formats (dict or string)\n",
    "            if isinstance(output, dict):\n",
    "                answer = output.get(\"result\", output)\n",
    "            else:\n",
    "                answer = output\n",
    "            batch_predictions.append(answer)\n",
    "        \n",
    "        predictions.extend(batch_predictions)\n",
    "        \n",
    "        # If ground truths are provided, compute and print batch metrics\n",
    "        if ground_truths:\n",
    "            batch_ground_truths = ground_truths[i:i+batch_size]\n",
    "            batch_metrics = calculate_metrics(batch_predictions, batch_ground_truths)\n",
    "            print(f\"Batch {i//batch_size + 1}/{num_batches} Metrics:\")\n",
    "            for key, value in batch_metrics.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "    return predictions\n",
    "def remove_punctuation(sentence):\n",
    "    if sentence[-1] == \".\":\n",
    "        return sentence[:-1]\n",
    "    else:\n",
    "        return sentence\n",
    "\n",
    "def calculate_metrics(predictions, ground_truths):\n",
    "    \"\"\"\n",
    "    Calculates evaluation metrics (recall, F1, exact match) for a list of predictions\n",
    "    compared to ground truths.\n",
    "    \"\"\"\n",
    "    # Ensure the lengths match\n",
    "    assert len(predictions) == len(ground_truths), \"Lengths of predictions and ground truths must match.\"\n",
    "    total_examples = len(predictions)\n",
    "    \n",
    "    exact_match_count = 0\n",
    "    total_recall = 0.0\n",
    "    total_precision = 0.0\n",
    "\n",
    "    for pred, gt in zip(predictions, ground_truths):\n",
    "        pred = pred.lower()\n",
    "        gt = gt.lower()\n",
    "        # Count exact matches\n",
    "        if pred == gt:\n",
    "            exact_match_count += 1\n",
    "        \n",
    "        # Tokenize the prediction and ground truth\n",
    "        pred_tokens = set(pred.split())\n",
    "        gt_tokens = set(gt.split())\n",
    "        \n",
    "        # Compute intersection of tokens\n",
    "        common_tokens = pred_tokens & gt_tokens\n",
    "        \n",
    "        # Compute recall and precision for the current pair\n",
    "        recall = len(common_tokens) / len(gt_tokens) if gt_tokens else 0\n",
    "        precision = len(common_tokens) / len(pred_tokens) if pred_tokens else 0\n",
    "        \n",
    "        total_recall += recall\n",
    "        total_precision += precision\n",
    "\n",
    "    # Compute average recall and precision\n",
    "    avg_recall = total_recall / total_examples\n",
    "    avg_precision = total_precision / total_examples\n",
    "    \n",
    "    # Calculate F1 score (harmonic mean)\n",
    "    f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "    exact_match = exact_match_count / total_examples\n",
    "\n",
    "    return {\n",
    "        \"recall\": avg_recall,\n",
    "        \"f1\": f1_score,\n",
    "        \"exact_match\": exact_match,\n",
    "        \"exact_match_count\": exact_match_count,\n",
    "        \"total_examples\": total_examples,\n",
    "        \"total_recall\": total_recall,\n",
    "        \"total_precision\": total_precision\n",
    "    }\n",
    "def extract_answer(answer):\n",
    "    import re\n",
    "\n",
    "    # Use a regex pattern to capture everything after \"Helpful Answer:\" until the end of the text\n",
    "    match = re.search(r\"(?i)Helpful Answer:\\s*(.*)\", answer, re.DOTALL)\n",
    "    if match:\n",
    "        answer_part = match.group(1).strip()\n",
    "        answer_part = answer_part.split(\"\\n\")[0]\n",
    "        return answer_part\n",
    "    else:\n",
    "        return \"Extract failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:07<00:00,  1.77s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "topk = 3\n",
    "# generation_model_name = \"google/flan-t5-base\"\n",
    "generation_model_name = \"Qwen/Qwen2-7B-Instruct\"\n",
    "ground_truths = None\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": topk})\n",
    "tokenizer = AutoTokenizer.from_pretrained(generation_model_name)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(generation_model_name, device_map=\"auto\")\n",
    "model = AutoModelForCausalLM.from_pretrained(generation_model_name, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "# model.config.use_cache = False\n",
    "model.eval()\n",
    "# pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, max_length=512)\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer, torch_dtype=torch.float16)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: {'source': '/home/ubuntu/ThreeRiversRAG/data/retrieve_source/total_web_txt/425.txt'}\n",
      "file: {'source': '/home/ubuntu/ThreeRiversRAG/data/retrieve_source/total_web_txt/445.txt'}\n",
      "file: {'source': '/home/ubuntu/ThreeRiversRAG/data/retrieve_source/total_web_txt/425.txt'}\n",
      "content: is overseen by a minimum of two district chiefs during normal daily operations. medic units are spread across pittsburgh better allowing for the most effective and efficient response. also, in coordination with the center for emergency medicine, a physician is able to respond to the scene at the request of our paramedics to assist with the treatment of particularly critical patients. in addition to emergency treatment and transport of patients, the ambulance division provides medical coverage\n",
      "content: pittsburgh through the worst of the crisis, helped to protect employees, residents, and visitors,” added director schmidt. pittsburgh is home to a unique emergency medical services (ems) system where physicians work side-by-side with paramedics and emergency medical technicians (emts); both in the field on emergency calls, but also during expansive training and medical protocol development efforts. “the bureau of emergency medical services is dedicated to saving the lives of pittsburgh’s\n",
      "content: to emergency treatment and transport of patients, the ambulance division provides medical coverage for special events throughout the city of pittsburgh. back to top contact us city of pittsburgh 414 grant st. pittsburgh, pa 15219 (accessibility entrance on ross st.) view on map 412-255-2621 share & connect like us on facebook follow us on x watch us on youtube get involved careers internships engagepgh explore pittsburgh disclaimers & polices | accessibility | privacy statement | sitemap © 2025\n"
     ]
    }
   ],
   "source": [
    "question = \"What department handles emergency medical services in the city of Pittsburgh?\"\n",
    "relevant_docs = vectorstore.similarity_search(question, k=3)\n",
    "for doc in relevant_docs:\n",
    "    print(f\"file: {doc.metadata}\")\n",
    "for doc in relevant_docs:\n",
    "    print(f\"content: {doc.page_content}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': \"Answer the question based only on the provided context in just one sentence. Each answer must be extremely succinct—limited to just several keywords—and should not repeat the question. If a question is a yes or no question, the answer must be exactly 'yes' or 'no' without any additional information.\\nQuestion: What department handles emergency medical services in the city of Pittsburgh?\", 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\napplications & forms one stop pgh permits licenses bulletins community resources code enforcement condemned buildings pli fees building codes appeals pli contacts announcements registrations innovation & performance sub-menu pittsburgh digital equity coalition public works sub-menu about public works contact public works environmental services architecture division street maintenance bureau forestry division zoning sub-menu zoning faq planning application and process planning reviews, public\\n\\napplications & forms one stop pgh permits licenses bulletins community resources code enforcement condemned buildings pli fees building codes appeals pli contacts announcements registrations innovation & performance sub-menu pittsburgh digital equity coalition public works sub-menu about public works contact public works environmental services architecture division street maintenance bureau forestry division zoning sub-menu zoning faq planning application and process planning reviews, public\\n\\napplications & forms one stop pgh permits licenses bulletins community resources code enforcement condemned buildings pli fees building codes appeals pli contacts announcements registrations innovation & performance sub-menu pittsburgh digital equity coalition public works sub-menu about public works contact public works environmental services architecture division street maintenance bureau forestry division zoning sub-menu zoning faq planning application and process planning reviews, public\\n\\nQuestion: Answer the question based only on the provided context in just one sentence. Each answer must be extremely succinct—limited to just several keywords—and should not repeat the question. If a question is a yes or no question, the answer must be exactly 'yes' or 'no' without any additional information.\\nQuestion: What department handles emergency medical services in the city of Pittsburgh?\\nHelpful Answer: Public Works does not handle emergency medical services.\"}\n",
      "Public Works does not handle emergency medical services.\n"
     ]
    }
   ],
   "source": [
    "# Define your custom instruction prompt\n",
    "ans_req = \"\"\"Answer the question based only on the provided context in just one sentence. Each answer must be extremely succinct—limited to just several keywords—and should not repeat the question.\"\"\"\n",
    "yes_or_no_req = \"\"\"If a question is a yes or no question, the answer must be exactly 'yes' or 'no' without any additional information.\"\"\"\n",
    "instruction_prompt = \" \".join([ans_req, yes_or_no_req])\n",
    "# Combine the instruction prompt with the question.\n",
    "final_prompt = f\"{instruction_prompt}\\nQuestion: {question}\"\n",
    "\n",
    "\n",
    "\n",
    "predictions = batch_inference(qa_chain, [final_prompt], 1, ground_truths if ground_truths else None)\n",
    "print(extract_answer(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "yes, there's the climate action plan in place\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recall': 0.0,\n",
       " 'f1': 0,\n",
       " 'exact_match': 0.0,\n",
       " 'exact_match_count': 0,\n",
       " 'total_examples': 1,\n",
       " 'total_recall': 0.0,\n",
       " 'total_precision': 0.0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = [\"yes\"]\n",
    "gt = [\"Yes, there's the Climate Action Plan in place.\"]\n",
    "calculate_metrics(ans, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
